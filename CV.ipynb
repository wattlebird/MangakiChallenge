{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'num_leaves': 60,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.96,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "#params = {\n",
    "#    'task': 'train',\n",
    "#    'boosting_type': 'rf',\n",
    "#    'objective': 'binary',\n",
    "#    'metric': {'auc'},\n",
    "#    'num_leaves': 400,\n",
    "#    'min_data_in_leaf': 2,\n",
    "#    'feature_fraction': 0.3,\n",
    "#    'bagging_fraction': 0.7,\n",
    "#    'bagging_freq': 1,\n",
    "#    'lambda_l1': 0,\n",
    "#    'min_gain_to_split': 0,\n",
    "#    'verbose': 0\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = \"/mnt/d/Data/mangaki-data-challenge/latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(train, valid):\n",
    "    X = lgb.Dataset(train.drop(['user_id', 'work_id', 'rating'], axis=1), train['rating'])\n",
    "    V = lgb.Dataset(valid.drop(['user_id', 'work_id', 'rating'], axis=1), valid['rating'], reference=X)\n",
    "    gbdt = lgb.train(params, X, valid_sets=[X,V], num_boost_round=200, early_stopping_rounds=20, verbose_eval=True)\n",
    "    Yvp = gbdt.predict(valid.drop(['user_id', 'work_id', 'rating'], axis=1), num_iteration=gbdt.best_iteration)\n",
    "    Ytp = gbdt.predict(train.drop(['user_id', 'work_id', 'rating'], axis=1), num_iteration=gbdt.best_iteration)\n",
    "    return (roc_auc_score(train['rating'].values, Ytp), roc_auc_score(valid['rating'].values, Yvp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(param, paramlst):\n",
    "    trainauc = [0.0]*len(paramlst)\n",
    "    validauc = [0.0]*len(paramlst)\n",
    "    for i, p in enumerate(paramlst):\n",
    "        params[param]=p\n",
    "        tv = [0,0,0]\n",
    "        vv = [0,0,0]\n",
    "        for fold in [1,2,3]:\n",
    "            t = pd.read_csv(data+'train_{0}.csv'.format(str(fold)))\n",
    "            v = pd.read_csv(data+'valid_{0}.csv'.format(str(fold)))\n",
    "            tv[fold-1], vv[fold-1] = training(t, v)\n",
    "        trainauc[i]=np.mean(tv)\n",
    "        validauc[i]=np.mean(vv)\n",
    "    paramtable = pd.DataFrame({\n",
    "        'TrainingSet': trainauc,\n",
    "        'ValidationSet': validauc\n",
    "    }, columns=['TrainingSet', 'ValidationSet'], index=pd.Index(paramlst, name=param))\n",
    "    print(paramtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.784762\tvalid_1's auc: 0.720833\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's auc: 0.811098\tvalid_1's auc: 0.742044\n",
      "[3]\ttraining's auc: 0.830911\tvalid_1's auc: 0.756794\n",
      "[4]\ttraining's auc: 0.840179\tvalid_1's auc: 0.761628\n",
      "[5]\ttraining's auc: 0.84904\tvalid_1's auc: 0.768451\n",
      "[6]\ttraining's auc: 0.855168\tvalid_1's auc: 0.772217\n",
      "[7]\ttraining's auc: 0.859819\tvalid_1's auc: 0.773952\n",
      "[8]\ttraining's auc: 0.864501\tvalid_1's auc: 0.776772\n",
      "[9]\ttraining's auc: 0.868825\tvalid_1's auc: 0.779215\n",
      "[10]\ttraining's auc: 0.873385\tvalid_1's auc: 0.780585\n",
      "[11]\ttraining's auc: 0.876527\tvalid_1's auc: 0.781114\n",
      "[12]\ttraining's auc: 0.881223\tvalid_1's auc: 0.78335\n",
      "[13]\ttraining's auc: 0.884312\tvalid_1's auc: 0.782719\n",
      "[14]\ttraining's auc: 0.889617\tvalid_1's auc: 0.785207\n",
      "[15]\ttraining's auc: 0.893603\tvalid_1's auc: 0.787159\n",
      "[16]\ttraining's auc: 0.897321\tvalid_1's auc: 0.786861\n",
      "[17]\ttraining's auc: 0.901607\tvalid_1's auc: 0.787091\n",
      "[18]\ttraining's auc: 0.904693\tvalid_1's auc: 0.789812\n",
      "[19]\ttraining's auc: 0.90793\tvalid_1's auc: 0.790608\n",
      "[20]\ttraining's auc: 0.91116\tvalid_1's auc: 0.791757\n",
      "[21]\ttraining's auc: 0.913786\tvalid_1's auc: 0.792888\n",
      "[22]\ttraining's auc: 0.916717\tvalid_1's auc: 0.79394\n",
      "[23]\ttraining's auc: 0.919792\tvalid_1's auc: 0.794233\n",
      "[24]\ttraining's auc: 0.923038\tvalid_1's auc: 0.796247\n",
      "[25]\ttraining's auc: 0.926397\tvalid_1's auc: 0.79586\n",
      "[26]\ttraining's auc: 0.928867\tvalid_1's auc: 0.795533\n",
      "[27]\ttraining's auc: 0.930945\tvalid_1's auc: 0.797029\n",
      "[28]\ttraining's auc: 0.933636\tvalid_1's auc: 0.798952\n",
      "[29]\ttraining's auc: 0.936358\tvalid_1's auc: 0.798961\n",
      "[30]\ttraining's auc: 0.938428\tvalid_1's auc: 0.800085\n",
      "[31]\ttraining's auc: 0.940177\tvalid_1's auc: 0.801489\n",
      "[32]\ttraining's auc: 0.942741\tvalid_1's auc: 0.801877\n",
      "[33]\ttraining's auc: 0.945117\tvalid_1's auc: 0.803178\n",
      "[34]\ttraining's auc: 0.946961\tvalid_1's auc: 0.804234\n",
      "[35]\ttraining's auc: 0.949026\tvalid_1's auc: 0.804772\n",
      "[36]\ttraining's auc: 0.950883\tvalid_1's auc: 0.805213\n",
      "[37]\ttraining's auc: 0.952486\tvalid_1's auc: 0.806748\n",
      "[38]\ttraining's auc: 0.954083\tvalid_1's auc: 0.808132\n",
      "[39]\ttraining's auc: 0.955648\tvalid_1's auc: 0.808296\n",
      "[40]\ttraining's auc: 0.957569\tvalid_1's auc: 0.808035\n",
      "[41]\ttraining's auc: 0.959081\tvalid_1's auc: 0.808407\n",
      "[42]\ttraining's auc: 0.960183\tvalid_1's auc: 0.808549\n",
      "[43]\ttraining's auc: 0.96161\tvalid_1's auc: 0.809318\n",
      "[44]\ttraining's auc: 0.962926\tvalid_1's auc: 0.808632\n",
      "[45]\ttraining's auc: 0.96458\tvalid_1's auc: 0.809178\n",
      "[46]\ttraining's auc: 0.965902\tvalid_1's auc: 0.809422\n",
      "[47]\ttraining's auc: 0.96726\tvalid_1's auc: 0.80973\n",
      "[48]\ttraining's auc: 0.9684\tvalid_1's auc: 0.809993\n",
      "[49]\ttraining's auc: 0.969628\tvalid_1's auc: 0.81114\n",
      "[50]\ttraining's auc: 0.970576\tvalid_1's auc: 0.812028\n",
      "[51]\ttraining's auc: 0.971533\tvalid_1's auc: 0.812886\n",
      "[52]\ttraining's auc: 0.972726\tvalid_1's auc: 0.812647\n",
      "[53]\ttraining's auc: 0.973867\tvalid_1's auc: 0.812957\n",
      "[54]\ttraining's auc: 0.97521\tvalid_1's auc: 0.812812\n",
      "[55]\ttraining's auc: 0.976136\tvalid_1's auc: 0.812722\n",
      "[56]\ttraining's auc: 0.977283\tvalid_1's auc: 0.812771\n",
      "[57]\ttraining's auc: 0.978126\tvalid_1's auc: 0.813599\n",
      "[58]\ttraining's auc: 0.97899\tvalid_1's auc: 0.813334\n",
      "[59]\ttraining's auc: 0.979734\tvalid_1's auc: 0.81323\n",
      "[60]\ttraining's auc: 0.980514\tvalid_1's auc: 0.813495\n",
      "[61]\ttraining's auc: 0.981619\tvalid_1's auc: 0.814161\n",
      "[62]\ttraining's auc: 0.982397\tvalid_1's auc: 0.813934\n",
      "[63]\ttraining's auc: 0.983059\tvalid_1's auc: 0.814689\n",
      "[64]\ttraining's auc: 0.983712\tvalid_1's auc: 0.815028\n",
      "[65]\ttraining's auc: 0.984553\tvalid_1's auc: 0.814612\n",
      "[66]\ttraining's auc: 0.985285\tvalid_1's auc: 0.814395\n",
      "[67]\ttraining's auc: 0.98596\tvalid_1's auc: 0.813825\n",
      "[68]\ttraining's auc: 0.986535\tvalid_1's auc: 0.813786\n",
      "[69]\ttraining's auc: 0.987214\tvalid_1's auc: 0.813916\n",
      "[70]\ttraining's auc: 0.987829\tvalid_1's auc: 0.813597\n",
      "[71]\ttraining's auc: 0.988414\tvalid_1's auc: 0.8138\n",
      "[72]\ttraining's auc: 0.988904\tvalid_1's auc: 0.813793\n",
      "[73]\ttraining's auc: 0.9895\tvalid_1's auc: 0.813454\n",
      "[74]\ttraining's auc: 0.99002\tvalid_1's auc: 0.813322\n",
      "[75]\ttraining's auc: 0.990538\tvalid_1's auc: 0.813459\n",
      "[76]\ttraining's auc: 0.990957\tvalid_1's auc: 0.813717\n",
      "[77]\ttraining's auc: 0.991447\tvalid_1's auc: 0.813858\n",
      "[78]\ttraining's auc: 0.991847\tvalid_1's auc: 0.814273\n",
      "[79]\ttraining's auc: 0.992164\tvalid_1's auc: 0.814675\n",
      "[80]\ttraining's auc: 0.992552\tvalid_1's auc: 0.81441\n",
      "[81]\ttraining's auc: 0.993003\tvalid_1's auc: 0.814547\n",
      "[82]\ttraining's auc: 0.993237\tvalid_1's auc: 0.81481\n",
      "[83]\ttraining's auc: 0.993681\tvalid_1's auc: 0.815218\n",
      "[84]\ttraining's auc: 0.994069\tvalid_1's auc: 0.815688\n",
      "[85]\ttraining's auc: 0.994416\tvalid_1's auc: 0.81523\n",
      "[86]\ttraining's auc: 0.994607\tvalid_1's auc: 0.815235\n",
      "[87]\ttraining's auc: 0.994966\tvalid_1's auc: 0.815661\n",
      "[88]\ttraining's auc: 0.995223\tvalid_1's auc: 0.815422\n",
      "[89]\ttraining's auc: 0.995529\tvalid_1's auc: 0.815746\n",
      "[90]\ttraining's auc: 0.995747\tvalid_1's auc: 0.816053\n",
      "[91]\ttraining's auc: 0.996004\tvalid_1's auc: 0.815873\n",
      "[92]\ttraining's auc: 0.99621\tvalid_1's auc: 0.815975\n",
      "[93]\ttraining's auc: 0.996374\tvalid_1's auc: 0.815803\n",
      "[94]\ttraining's auc: 0.996627\tvalid_1's auc: 0.815659\n",
      "[95]\ttraining's auc: 0.996823\tvalid_1's auc: 0.815737\n",
      "[96]\ttraining's auc: 0.99705\tvalid_1's auc: 0.81612\n",
      "[97]\ttraining's auc: 0.997206\tvalid_1's auc: 0.816316\n",
      "[98]\ttraining's auc: 0.997372\tvalid_1's auc: 0.816008\n",
      "[99]\ttraining's auc: 0.997556\tvalid_1's auc: 0.816203\n",
      "[100]\ttraining's auc: 0.997727\tvalid_1's auc: 0.815781\n",
      "[101]\ttraining's auc: 0.997922\tvalid_1's auc: 0.815564\n",
      "[102]\ttraining's auc: 0.998008\tvalid_1's auc: 0.81563\n",
      "[103]\ttraining's auc: 0.998109\tvalid_1's auc: 0.815627\n",
      "[104]\ttraining's auc: 0.998245\tvalid_1's auc: 0.815349\n",
      "[105]\ttraining's auc: 0.998384\tvalid_1's auc: 0.814832\n",
      "[106]\ttraining's auc: 0.998467\tvalid_1's auc: 0.814489\n",
      "[107]\ttraining's auc: 0.998568\tvalid_1's auc: 0.81442\n",
      "[108]\ttraining's auc: 0.998644\tvalid_1's auc: 0.814294\n",
      "[109]\ttraining's auc: 0.998732\tvalid_1's auc: 0.814024\n",
      "[110]\ttraining's auc: 0.998832\tvalid_1's auc: 0.813864\n",
      "[111]\ttraining's auc: 0.998923\tvalid_1's auc: 0.813803\n",
      "[112]\ttraining's auc: 0.998998\tvalid_1's auc: 0.813704\n",
      "[113]\ttraining's auc: 0.999048\tvalid_1's auc: 0.813704\n",
      "[114]\ttraining's auc: 0.999127\tvalid_1's auc: 0.813644\n",
      "[115]\ttraining's auc: 0.999174\tvalid_1's auc: 0.813942\n",
      "[116]\ttraining's auc: 0.999226\tvalid_1's auc: 0.814127\n",
      "[117]\ttraining's auc: 0.999319\tvalid_1's auc: 0.813998\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's auc: 0.997206\tvalid_1's auc: 0.816316\n",
      "[1]\ttraining's auc: 0.780499\tvalid_1's auc: 0.703333\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's auc: 0.812234\tvalid_1's auc: 0.731528\n",
      "[3]\ttraining's auc: 0.833436\tvalid_1's auc: 0.747785\n",
      "[4]\ttraining's auc: 0.843403\tvalid_1's auc: 0.757253\n",
      "[5]\ttraining's auc: 0.849869\tvalid_1's auc: 0.761207\n",
      "[6]\ttraining's auc: 0.854899\tvalid_1's auc: 0.766745\n",
      "[7]\ttraining's auc: 0.860216\tvalid_1's auc: 0.767443\n",
      "[8]\ttraining's auc: 0.865571\tvalid_1's auc: 0.769426\n",
      "[9]\ttraining's auc: 0.869588\tvalid_1's auc: 0.771024\n",
      "[10]\ttraining's auc: 0.875372\tvalid_1's auc: 0.773434\n",
      "[11]\ttraining's auc: 0.879755\tvalid_1's auc: 0.774874\n",
      "[12]\ttraining's auc: 0.884287\tvalid_1's auc: 0.776549\n",
      "[13]\ttraining's auc: 0.888556\tvalid_1's auc: 0.779268\n",
      "[14]\ttraining's auc: 0.892252\tvalid_1's auc: 0.780685\n",
      "[15]\ttraining's auc: 0.896151\tvalid_1's auc: 0.784504\n",
      "[16]\ttraining's auc: 0.899363\tvalid_1's auc: 0.785109\n",
      "[17]\ttraining's auc: 0.903252\tvalid_1's auc: 0.787547\n",
      "[18]\ttraining's auc: 0.906951\tvalid_1's auc: 0.789541\n",
      "[19]\ttraining's auc: 0.910445\tvalid_1's auc: 0.789573\n",
      "[20]\ttraining's auc: 0.913628\tvalid_1's auc: 0.791178\n",
      "[21]\ttraining's auc: 0.917005\tvalid_1's auc: 0.793442\n",
      "[22]\ttraining's auc: 0.920153\tvalid_1's auc: 0.795474\n",
      "[23]\ttraining's auc: 0.923006\tvalid_1's auc: 0.797231\n",
      "[24]\ttraining's auc: 0.925854\tvalid_1's auc: 0.798137\n",
      "[25]\ttraining's auc: 0.928142\tvalid_1's auc: 0.798554\n",
      "[26]\ttraining's auc: 0.931329\tvalid_1's auc: 0.799232\n",
      "[27]\ttraining's auc: 0.933684\tvalid_1's auc: 0.799676\n",
      "[28]\ttraining's auc: 0.935968\tvalid_1's auc: 0.799893\n",
      "[29]\ttraining's auc: 0.938774\tvalid_1's auc: 0.800197\n",
      "[30]\ttraining's auc: 0.940994\tvalid_1's auc: 0.800459\n",
      "[31]\ttraining's auc: 0.94302\tvalid_1's auc: 0.801694\n",
      "[32]\ttraining's auc: 0.945566\tvalid_1's auc: 0.802411\n",
      "[33]\ttraining's auc: 0.947366\tvalid_1's auc: 0.802782\n",
      "[34]\ttraining's auc: 0.94933\tvalid_1's auc: 0.802618\n",
      "[35]\ttraining's auc: 0.951316\tvalid_1's auc: 0.803143\n",
      "[36]\ttraining's auc: 0.953018\tvalid_1's auc: 0.803516\n",
      "[37]\ttraining's auc: 0.954917\tvalid_1's auc: 0.803756\n",
      "[38]\ttraining's auc: 0.956614\tvalid_1's auc: 0.804321\n",
      "[39]\ttraining's auc: 0.958234\tvalid_1's auc: 0.804698\n",
      "[40]\ttraining's auc: 0.960057\tvalid_1's auc: 0.804874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\ttraining's auc: 0.961509\tvalid_1's auc: 0.80529\n",
      "[42]\ttraining's auc: 0.962834\tvalid_1's auc: 0.805481\n",
      "[43]\ttraining's auc: 0.964121\tvalid_1's auc: 0.805576\n",
      "[44]\ttraining's auc: 0.965524\tvalid_1's auc: 0.806144\n",
      "[45]\ttraining's auc: 0.966966\tvalid_1's auc: 0.806629\n",
      "[46]\ttraining's auc: 0.968115\tvalid_1's auc: 0.806559\n",
      "[47]\ttraining's auc: 0.969496\tvalid_1's auc: 0.807082\n",
      "[48]\ttraining's auc: 0.970793\tvalid_1's auc: 0.806851\n",
      "[49]\ttraining's auc: 0.971939\tvalid_1's auc: 0.807248\n",
      "[50]\ttraining's auc: 0.973029\tvalid_1's auc: 0.807514\n",
      "[51]\ttraining's auc: 0.974361\tvalid_1's auc: 0.807186\n",
      "[52]\ttraining's auc: 0.975376\tvalid_1's auc: 0.807217\n",
      "[53]\ttraining's auc: 0.976868\tvalid_1's auc: 0.807019\n",
      "[54]\ttraining's auc: 0.977683\tvalid_1's auc: 0.807309\n",
      "[55]\ttraining's auc: 0.978603\tvalid_1's auc: 0.80709\n",
      "[56]\ttraining's auc: 0.979804\tvalid_1's auc: 0.807117\n",
      "[57]\ttraining's auc: 0.980709\tvalid_1's auc: 0.807223\n",
      "[58]\ttraining's auc: 0.981874\tvalid_1's auc: 0.80746\n",
      "[59]\ttraining's auc: 0.982741\tvalid_1's auc: 0.807319\n",
      "[60]\ttraining's auc: 0.983475\tvalid_1's auc: 0.807806\n",
      "[61]\ttraining's auc: 0.984234\tvalid_1's auc: 0.808056\n",
      "[62]\ttraining's auc: 0.984733\tvalid_1's auc: 0.8083\n",
      "[63]\ttraining's auc: 0.98542\tvalid_1's auc: 0.808511\n",
      "[64]\ttraining's auc: 0.986188\tvalid_1's auc: 0.808795\n",
      "[65]\ttraining's auc: 0.986768\tvalid_1's auc: 0.808408\n",
      "[66]\ttraining's auc: 0.987487\tvalid_1's auc: 0.808104\n",
      "[67]\ttraining's auc: 0.988112\tvalid_1's auc: 0.808178\n",
      "[68]\ttraining's auc: 0.988477\tvalid_1's auc: 0.808635\n",
      "[69]\ttraining's auc: 0.989009\tvalid_1's auc: 0.808864\n",
      "[70]\ttraining's auc: 0.989525\tvalid_1's auc: 0.809244\n",
      "[71]\ttraining's auc: 0.990223\tvalid_1's auc: 0.809158\n",
      "[72]\ttraining's auc: 0.990686\tvalid_1's auc: 0.809425\n",
      "[73]\ttraining's auc: 0.991069\tvalid_1's auc: 0.80943\n",
      "[74]\ttraining's auc: 0.991578\tvalid_1's auc: 0.809282\n",
      "[75]\ttraining's auc: 0.992034\tvalid_1's auc: 0.809267\n",
      "[76]\ttraining's auc: 0.992371\tvalid_1's auc: 0.809822\n",
      "[77]\ttraining's auc: 0.992686\tvalid_1's auc: 0.809551\n",
      "[78]\ttraining's auc: 0.993039\tvalid_1's auc: 0.809294\n",
      "[79]\ttraining's auc: 0.993412\tvalid_1's auc: 0.809411\n",
      "[80]\ttraining's auc: 0.993739\tvalid_1's auc: 0.809231\n",
      "[81]\ttraining's auc: 0.994067\tvalid_1's auc: 0.808873\n",
      "[82]\ttraining's auc: 0.994419\tvalid_1's auc: 0.808788\n",
      "[83]\ttraining's auc: 0.994806\tvalid_1's auc: 0.808854\n",
      "[84]\ttraining's auc: 0.995077\tvalid_1's auc: 0.808879\n",
      "[85]\ttraining's auc: 0.995437\tvalid_1's auc: 0.808457\n",
      "[86]\ttraining's auc: 0.995619\tvalid_1's auc: 0.808602\n",
      "[87]\ttraining's auc: 0.99584\tvalid_1's auc: 0.809309\n",
      "[88]\ttraining's auc: 0.996027\tvalid_1's auc: 0.809219\n",
      "[89]\ttraining's auc: 0.99628\tvalid_1's auc: 0.809337\n",
      "[90]\ttraining's auc: 0.996491\tvalid_1's auc: 0.809074\n",
      "[91]\ttraining's auc: 0.996684\tvalid_1's auc: 0.809325\n",
      "[92]\ttraining's auc: 0.996883\tvalid_1's auc: 0.809206\n",
      "[93]\ttraining's auc: 0.997051\tvalid_1's auc: 0.808923\n",
      "[94]\ttraining's auc: 0.997191\tvalid_1's auc: 0.809208\n",
      "[95]\ttraining's auc: 0.997375\tvalid_1's auc: 0.808832\n",
      "[96]\ttraining's auc: 0.997502\tvalid_1's auc: 0.808837\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's auc: 0.992371\tvalid_1's auc: 0.809822\n",
      "[1]\ttraining's auc: 0.7816\tvalid_1's auc: 0.703516\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's auc: 0.813301\tvalid_1's auc: 0.733321\n",
      "[3]\ttraining's auc: 0.83624\tvalid_1's auc: 0.755287\n",
      "[4]\ttraining's auc: 0.845208\tvalid_1's auc: 0.760693\n",
      "[5]\ttraining's auc: 0.852977\tvalid_1's auc: 0.766856\n",
      "[6]\ttraining's auc: 0.857107\tvalid_1's auc: 0.769152\n",
      "[7]\ttraining's auc: 0.861846\tvalid_1's auc: 0.771674\n",
      "[8]\ttraining's auc: 0.865928\tvalid_1's auc: 0.773644\n",
      "[9]\ttraining's auc: 0.869279\tvalid_1's auc: 0.773436\n",
      "[10]\ttraining's auc: 0.875188\tvalid_1's auc: 0.776245\n",
      "[11]\ttraining's auc: 0.878286\tvalid_1's auc: 0.777293\n",
      "[12]\ttraining's auc: 0.881814\tvalid_1's auc: 0.779114\n",
      "[13]\ttraining's auc: 0.885203\tvalid_1's auc: 0.780381\n",
      "[14]\ttraining's auc: 0.890007\tvalid_1's auc: 0.783704\n",
      "[15]\ttraining's auc: 0.893319\tvalid_1's auc: 0.784248\n",
      "[16]\ttraining's auc: 0.898265\tvalid_1's auc: 0.786811\n",
      "[17]\ttraining's auc: 0.901818\tvalid_1's auc: 0.788155\n",
      "[18]\ttraining's auc: 0.904901\tvalid_1's auc: 0.788566\n",
      "[19]\ttraining's auc: 0.907826\tvalid_1's auc: 0.789581\n",
      "[20]\ttraining's auc: 0.910815\tvalid_1's auc: 0.791013\n",
      "[21]\ttraining's auc: 0.914033\tvalid_1's auc: 0.791703\n",
      "[22]\ttraining's auc: 0.917737\tvalid_1's auc: 0.793916\n",
      "[23]\ttraining's auc: 0.921249\tvalid_1's auc: 0.793806\n",
      "[24]\ttraining's auc: 0.924194\tvalid_1's auc: 0.794202\n",
      "[25]\ttraining's auc: 0.92674\tvalid_1's auc: 0.795789\n",
      "[26]\ttraining's auc: 0.929513\tvalid_1's auc: 0.795967\n",
      "[27]\ttraining's auc: 0.931765\tvalid_1's auc: 0.798022\n",
      "[28]\ttraining's auc: 0.933927\tvalid_1's auc: 0.798326\n",
      "[29]\ttraining's auc: 0.936489\tvalid_1's auc: 0.798221\n",
      "[30]\ttraining's auc: 0.938909\tvalid_1's auc: 0.799124\n",
      "[31]\ttraining's auc: 0.941121\tvalid_1's auc: 0.800117\n",
      "[32]\ttraining's auc: 0.943088\tvalid_1's auc: 0.800568\n",
      "[33]\ttraining's auc: 0.945088\tvalid_1's auc: 0.8004\n",
      "[34]\ttraining's auc: 0.947526\tvalid_1's auc: 0.800502\n",
      "[35]\ttraining's auc: 0.949662\tvalid_1's auc: 0.800874\n",
      "[36]\ttraining's auc: 0.951306\tvalid_1's auc: 0.801142\n",
      "[37]\ttraining's auc: 0.952983\tvalid_1's auc: 0.801703\n",
      "[38]\ttraining's auc: 0.954508\tvalid_1's auc: 0.802119\n",
      "[39]\ttraining's auc: 0.955842\tvalid_1's auc: 0.80293\n",
      "[40]\ttraining's auc: 0.957625\tvalid_1's auc: 0.802514\n",
      "[41]\ttraining's auc: 0.958845\tvalid_1's auc: 0.803333\n",
      "[42]\ttraining's auc: 0.960525\tvalid_1's auc: 0.80345\n",
      "[43]\ttraining's auc: 0.962571\tvalid_1's auc: 0.803405\n",
      "[44]\ttraining's auc: 0.963869\tvalid_1's auc: 0.803724\n",
      "[45]\ttraining's auc: 0.965585\tvalid_1's auc: 0.804367\n",
      "[46]\ttraining's auc: 0.96694\tvalid_1's auc: 0.804558\n",
      "[47]\ttraining's auc: 0.968151\tvalid_1's auc: 0.804415\n",
      "[48]\ttraining's auc: 0.969152\tvalid_1's auc: 0.80472\n",
      "[49]\ttraining's auc: 0.97033\tvalid_1's auc: 0.804701\n",
      "[50]\ttraining's auc: 0.971632\tvalid_1's auc: 0.805136\n",
      "[51]\ttraining's auc: 0.972726\tvalid_1's auc: 0.80564\n",
      "[52]\ttraining's auc: 0.973678\tvalid_1's auc: 0.805294\n",
      "[53]\ttraining's auc: 0.974838\tvalid_1's auc: 0.805105\n",
      "[54]\ttraining's auc: 0.975807\tvalid_1's auc: 0.805451\n",
      "[55]\ttraining's auc: 0.976518\tvalid_1's auc: 0.805981\n",
      "[56]\ttraining's auc: 0.977416\tvalid_1's auc: 0.805893\n",
      "[57]\ttraining's auc: 0.97838\tvalid_1's auc: 0.806397\n",
      "[58]\ttraining's auc: 0.979194\tvalid_1's auc: 0.806765\n",
      "[59]\ttraining's auc: 0.97984\tvalid_1's auc: 0.8069\n",
      "[60]\ttraining's auc: 0.980817\tvalid_1's auc: 0.807176\n",
      "[61]\ttraining's auc: 0.981679\tvalid_1's auc: 0.807067\n",
      "[62]\ttraining's auc: 0.982321\tvalid_1's auc: 0.80715\n",
      "[63]\ttraining's auc: 0.983118\tvalid_1's auc: 0.80707\n",
      "[64]\ttraining's auc: 0.983758\tvalid_1's auc: 0.80689\n",
      "[65]\ttraining's auc: 0.984249\tvalid_1's auc: 0.807179\n",
      "[66]\ttraining's auc: 0.984798\tvalid_1's auc: 0.807029\n",
      "[67]\ttraining's auc: 0.985337\tvalid_1's auc: 0.806977\n",
      "[68]\ttraining's auc: 0.985982\tvalid_1's auc: 0.806987\n",
      "[69]\ttraining's auc: 0.986529\tvalid_1's auc: 0.80717\n",
      "[70]\ttraining's auc: 0.987098\tvalid_1's auc: 0.80724\n",
      "[71]\ttraining's auc: 0.987683\tvalid_1's auc: 0.807234\n",
      "[72]\ttraining's auc: 0.988116\tvalid_1's auc: 0.807902\n",
      "[73]\ttraining's auc: 0.988645\tvalid_1's auc: 0.808479\n",
      "[74]\ttraining's auc: 0.989302\tvalid_1's auc: 0.808485\n",
      "[75]\ttraining's auc: 0.989834\tvalid_1's auc: 0.808709\n",
      "[76]\ttraining's auc: 0.990403\tvalid_1's auc: 0.808498\n",
      "[77]\ttraining's auc: 0.99093\tvalid_1's auc: 0.808056\n",
      "[78]\ttraining's auc: 0.991376\tvalid_1's auc: 0.807811\n",
      "[79]\ttraining's auc: 0.991787\tvalid_1's auc: 0.807594\n",
      "[80]\ttraining's auc: 0.99216\tvalid_1's auc: 0.808565\n",
      "[81]\ttraining's auc: 0.992494\tvalid_1's auc: 0.808316\n",
      "[82]\ttraining's auc: 0.992932\tvalid_1's auc: 0.808364\n",
      "[83]\ttraining's auc: 0.99328\tvalid_1's auc: 0.808497\n",
      "[84]\ttraining's auc: 0.993589\tvalid_1's auc: 0.808806\n",
      "[85]\ttraining's auc: 0.993892\tvalid_1's auc: 0.808605\n",
      "[86]\ttraining's auc: 0.99434\tvalid_1's auc: 0.808541\n",
      "[87]\ttraining's auc: 0.994644\tvalid_1's auc: 0.808602\n",
      "[88]\ttraining's auc: 0.994938\tvalid_1's auc: 0.808818\n",
      "[89]\ttraining's auc: 0.995149\tvalid_1's auc: 0.809203\n",
      "[90]\ttraining's auc: 0.99535\tvalid_1's auc: 0.809325\n",
      "[91]\ttraining's auc: 0.995546\tvalid_1's auc: 0.809335\n",
      "[92]\ttraining's auc: 0.995704\tvalid_1's auc: 0.809001\n",
      "[93]\ttraining's auc: 0.995899\tvalid_1's auc: 0.809039\n",
      "[94]\ttraining's auc: 0.996141\tvalid_1's auc: 0.809044\n",
      "[95]\ttraining's auc: 0.996255\tvalid_1's auc: 0.809292\n",
      "[96]\ttraining's auc: 0.996429\tvalid_1's auc: 0.809538\n",
      "[97]\ttraining's auc: 0.99663\tvalid_1's auc: 0.809635\n",
      "[98]\ttraining's auc: 0.996864\tvalid_1's auc: 0.809889\n",
      "[99]\ttraining's auc: 0.997074\tvalid_1's auc: 0.809939\n",
      "[100]\ttraining's auc: 0.997241\tvalid_1's auc: 0.809821\n",
      "[101]\ttraining's auc: 0.997372\tvalid_1's auc: 0.809826\n",
      "[102]\ttraining's auc: 0.997524\tvalid_1's auc: 0.809747\n",
      "[103]\ttraining's auc: 0.997668\tvalid_1's auc: 0.809742\n",
      "[104]\ttraining's auc: 0.99784\tvalid_1's auc: 0.809617\n",
      "[105]\ttraining's auc: 0.998051\tvalid_1's auc: 0.809179\n",
      "[106]\ttraining's auc: 0.998157\tvalid_1's auc: 0.809442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107]\ttraining's auc: 0.998276\tvalid_1's auc: 0.809761\n",
      "[108]\ttraining's auc: 0.998359\tvalid_1's auc: 0.810173\n",
      "[109]\ttraining's auc: 0.998492\tvalid_1's auc: 0.810527\n",
      "[110]\ttraining's auc: 0.998564\tvalid_1's auc: 0.810464\n",
      "[111]\ttraining's auc: 0.998633\tvalid_1's auc: 0.811064\n",
      "[112]\ttraining's auc: 0.998708\tvalid_1's auc: 0.811022\n",
      "[113]\ttraining's auc: 0.998753\tvalid_1's auc: 0.810849\n",
      "[114]\ttraining's auc: 0.998797\tvalid_1's auc: 0.810767\n",
      "[115]\ttraining's auc: 0.998854\tvalid_1's auc: 0.810819\n",
      "[116]\ttraining's auc: 0.998898\tvalid_1's auc: 0.810976\n",
      "[117]\ttraining's auc: 0.998951\tvalid_1's auc: 0.810921\n",
      "[118]\ttraining's auc: 0.998996\tvalid_1's auc: 0.810624\n",
      "[119]\ttraining's auc: 0.999077\tvalid_1's auc: 0.81074\n",
      "[120]\ttraining's auc: 0.999135\tvalid_1's auc: 0.81057\n",
      "[121]\ttraining's auc: 0.999198\tvalid_1's auc: 0.810472\n",
      "[122]\ttraining's auc: 0.999241\tvalid_1's auc: 0.810354\n",
      "[123]\ttraining's auc: 0.999291\tvalid_1's auc: 0.810562\n",
      "[124]\ttraining's auc: 0.999321\tvalid_1's auc: 0.810849\n",
      "[125]\ttraining's auc: 0.999355\tvalid_1's auc: 0.810743\n",
      "[126]\ttraining's auc: 0.999394\tvalid_1's auc: 0.810327\n",
      "[127]\ttraining's auc: 0.999416\tvalid_1's auc: 0.810278\n",
      "[128]\ttraining's auc: 0.999447\tvalid_1's auc: 0.810483\n",
      "[129]\ttraining's auc: 0.999497\tvalid_1's auc: 0.810512\n",
      "[130]\ttraining's auc: 0.99953\tvalid_1's auc: 0.811023\n",
      "[131]\ttraining's auc: 0.999558\tvalid_1's auc: 0.81109\n",
      "[132]\ttraining's auc: 0.999576\tvalid_1's auc: 0.811109\n",
      "[133]\ttraining's auc: 0.999595\tvalid_1's auc: 0.811053\n",
      "[134]\ttraining's auc: 0.999631\tvalid_1's auc: 0.81088\n",
      "[135]\ttraining's auc: 0.999652\tvalid_1's auc: 0.810917\n",
      "[136]\ttraining's auc: 0.99967\tvalid_1's auc: 0.810876\n",
      "[137]\ttraining's auc: 0.999697\tvalid_1's auc: 0.811136\n",
      "[138]\ttraining's auc: 0.999722\tvalid_1's auc: 0.81147\n",
      "[139]\ttraining's auc: 0.999736\tvalid_1's auc: 0.811587\n",
      "[140]\ttraining's auc: 0.999755\tvalid_1's auc: 0.811602\n",
      "[141]\ttraining's auc: 0.999763\tvalid_1's auc: 0.811549\n",
      "[142]\ttraining's auc: 0.999769\tvalid_1's auc: 0.811535\n",
      "[143]\ttraining's auc: 0.999791\tvalid_1's auc: 0.812011\n",
      "[144]\ttraining's auc: 0.999802\tvalid_1's auc: 0.812452\n",
      "[145]\ttraining's auc: 0.999829\tvalid_1's auc: 0.812596\n",
      "[146]\ttraining's auc: 0.999836\tvalid_1's auc: 0.812711\n",
      "[147]\ttraining's auc: 0.999845\tvalid_1's auc: 0.812879\n",
      "[148]\ttraining's auc: 0.999851\tvalid_1's auc: 0.812923\n",
      "[149]\ttraining's auc: 0.999856\tvalid_1's auc: 0.812723\n",
      "[150]\ttraining's auc: 0.999866\tvalid_1's auc: 0.812653\n",
      "[151]\ttraining's auc: 0.999874\tvalid_1's auc: 0.812591\n",
      "[152]\ttraining's auc: 0.999881\tvalid_1's auc: 0.812635\n",
      "[153]\ttraining's auc: 0.999892\tvalid_1's auc: 0.812378\n",
      "[154]\ttraining's auc: 0.9999\tvalid_1's auc: 0.812211\n",
      "[155]\ttraining's auc: 0.999909\tvalid_1's auc: 0.812251\n",
      "[156]\ttraining's auc: 0.999924\tvalid_1's auc: 0.812384\n",
      "[157]\ttraining's auc: 0.999928\tvalid_1's auc: 0.812658\n",
      "[158]\ttraining's auc: 0.999939\tvalid_1's auc: 0.812521\n",
      "[159]\ttraining's auc: 0.999943\tvalid_1's auc: 0.812553\n",
      "[160]\ttraining's auc: 0.999949\tvalid_1's auc: 0.812387\n",
      "[161]\ttraining's auc: 0.999951\tvalid_1's auc: 0.812118\n",
      "[162]\ttraining's auc: 0.999953\tvalid_1's auc: 0.812112\n",
      "[163]\ttraining's auc: 0.999957\tvalid_1's auc: 0.812322\n",
      "[164]\ttraining's auc: 0.99996\tvalid_1's auc: 0.812254\n",
      "[165]\ttraining's auc: 0.999962\tvalid_1's auc: 0.812262\n",
      "[166]\ttraining's auc: 0.999964\tvalid_1's auc: 0.81221\n",
      "[167]\ttraining's auc: 0.999968\tvalid_1's auc: 0.812359\n",
      "[168]\ttraining's auc: 0.999971\tvalid_1's auc: 0.812309\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's auc: 0.999851\tvalid_1's auc: 0.812923\n",
      "                  TrainingSet  ValidationSet\n",
      "feature_fraction                            \n",
      "0.6                  0.996476        0.81302\n"
     ]
    }
   ],
   "source": [
    "cv('feature_fraction', [0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LibFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "path = \"/mnt/d/Data/mangaki-data-challenge/libfm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, ty = load_svmlight_file(path+\"train_1.csv\")\n",
    "valid, vy = load_svmlight_file(path+\"valid_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_append = pd.read_csv(data+\"train_1.csv\").fillna(0)\n",
    "valid_append = pd.read_csv(data+\"valid_1.csv\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemw2vpos_0_x</th>\n",
       "      <th>itemw2vpos_1_x</th>\n",
       "      <th>itemw2vpos_2_x</th>\n",
       "      <th>itemw2vpos_3_x</th>\n",
       "      <th>itemw2vpos_4_x</th>\n",
       "      <th>itemw2vpos_5_x</th>\n",
       "      <th>itemw2vpos_6_x</th>\n",
       "      <th>itemw2vpos_7_x</th>\n",
       "      <th>itemw2vpos_8_x</th>\n",
       "      <th>itemw2vpos_9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>user_ldapos_10</th>\n",
       "      <th>user_ldapos_11</th>\n",
       "      <th>user_ldapos_12</th>\n",
       "      <th>user_ldapos_13</th>\n",
       "      <th>user_ldapos_14</th>\n",
       "      <th>user_ldapos_15</th>\n",
       "      <th>user_ldapos_16</th>\n",
       "      <th>user_ldapos_17</th>\n",
       "      <th>user_ldapos_18</th>\n",
       "      <th>user_ldapos_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.158782</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>-0.196929</td>\n",
       "      <td>-0.139314</td>\n",
       "      <td>-0.196677</td>\n",
       "      <td>-0.253198</td>\n",
       "      <td>0.124238</td>\n",
       "      <td>-0.289648</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.417720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075337</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.232903</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>-0.257882</td>\n",
       "      <td>-0.262738</td>\n",
       "      <td>-0.262490</td>\n",
       "      <td>-0.365255</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>-0.459551</td>\n",
       "      <td>0.111113</td>\n",
       "      <td>0.768426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044899</td>\n",
       "      <td>0.066113</td>\n",
       "      <td>-0.091652</td>\n",
       "      <td>-0.098183</td>\n",
       "      <td>-0.142543</td>\n",
       "      <td>-0.129436</td>\n",
       "      <td>0.072879</td>\n",
       "      <td>-0.166809</td>\n",
       "      <td>0.057120</td>\n",
       "      <td>0.274530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemw2vpos_0_x  itemw2vpos_1_x  itemw2vpos_2_x  itemw2vpos_3_x  \\\n",
       "0       -0.158782        0.011554       -0.196929       -0.139314   \n",
       "1             NaN             NaN             NaN             NaN   \n",
       "2             NaN             NaN             NaN             NaN   \n",
       "3       -0.232903        0.074238       -0.257882       -0.262738   \n",
       "4       -0.044899        0.066113       -0.091652       -0.098183   \n",
       "\n",
       "   itemw2vpos_4_x  itemw2vpos_5_x  itemw2vpos_6_x  itemw2vpos_7_x  \\\n",
       "0       -0.196677       -0.253198        0.124238       -0.289648   \n",
       "1             NaN             NaN             NaN             NaN   \n",
       "2             NaN             NaN             NaN             NaN   \n",
       "3       -0.262490       -0.365255        0.189333       -0.459551   \n",
       "4       -0.142543       -0.129436        0.072879       -0.166809   \n",
       "\n",
       "   itemw2vpos_8_x  itemw2vpos_9_x       ...        user_ldapos_10  \\\n",
       "0        0.055328        0.417720       ...                   0.0   \n",
       "1             NaN             NaN       ...                   0.0   \n",
       "2             NaN             NaN       ...                   0.0   \n",
       "3        0.111113        0.768426       ...                   0.0   \n",
       "4        0.057120        0.274530       ...                   0.0   \n",
       "\n",
       "   user_ldapos_11  user_ldapos_12  user_ldapos_13  user_ldapos_14  \\\n",
       "0             0.0             0.0        0.000000             0.0   \n",
       "1             0.0             0.0        0.000000             0.0   \n",
       "2             0.0             0.0        0.285676             0.0   \n",
       "3             0.0             0.0        0.000000             0.0   \n",
       "4             0.0             0.0        0.000000             0.0   \n",
       "\n",
       "   user_ldapos_15  user_ldapos_16  user_ldapos_17  user_ldapos_18  \\\n",
       "0             0.0             0.0             0.0        0.075337   \n",
       "1             0.0             0.0             0.0        0.000000   \n",
       "2             0.0             0.0             0.0        0.000000   \n",
       "3             0.0             0.0             0.0        0.000000   \n",
       "4             0.0             0.0             0.0        0.000000   \n",
       "\n",
       "   user_ldapos_19  \n",
       "0        0.000000  \n",
       "1        0.077270  \n",
       "2        0.000000  \n",
       "3        0.000000  \n",
       "4        0.422931  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_append.ix[:, 15:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7441x12015 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 711750 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "hstack([train, train_append.ix[:, 15:].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_iter':200, \n",
    "    'init_stdev':0.001,\n",
    "    'l2_reg_w':0.01,\n",
    "    'l2_reg_V':0.1,\n",
    "    'rank':10,\n",
    "    'step_size':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastFM import sgd\n",
    "\n",
    "fm = sgd.FMClassification(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.l2_reg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set AUC 0.8856164958057352; validation set AUC 0.795728824146936.\n"
     ]
    }
   ],
   "source": [
    "fm.fit(train, np.require(ty*2-1, dtype=np.int))\n",
    "print(\"Training set AUC {0}; validation set AUC {1}.\".format(roc_auc_score(ty, fm.predict_proba(train)), roc_auc_score(vy, fm.predict_proba(valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from fastFM import sgd\n",
    "\n",
    "def train_fm(train, valid, trainy, validy):\n",
    "    fm = sgd.FMClassification(**params)\n",
    "    fm.fit(train, np.require(trainy*2-1, dtype=np.int))\n",
    "    return (roc_auc_score(trainy, fm.predict_proba(train)), roc_auc_score(validy, fm.predict_proba(valid)))\n",
    "\n",
    "def cv_fm(param, paramlst):\n",
    "    trainauc = [0.0]*len(paramlst)\n",
    "    validauc = [0.0]*len(paramlst)\n",
    "    for i, p in enumerate(paramlst):\n",
    "        params[param]=p\n",
    "        tv = [0,0,0]\n",
    "        vv = [0,0,0]\n",
    "        for fold in [1,2,3]:\n",
    "            train, ty = load_svmlight_file(path+\"train_{0}.csv\".format(fold))\n",
    "            valid, vy = load_svmlight_file(path+\"valid_{0}.csv\".format(fold))\n",
    "            ta = pd.read_csv(data+'train_{0}.csv'.format(str(fold))).fillna(0)\n",
    "            va = pd.read_csv(data+'valid_{0}.csv'.format(str(fold))).fillna(0)\n",
    "            #train = hstack([train, ta.ix[:, 15:].values])\n",
    "            #valid = hstack([valid, va.ix[:, 15:].values])\n",
    "            tv[fold-1], vv[fold-1] = train_fm(train, valid, ty, vy)\n",
    "        trainauc[i]=np.mean(tv)\n",
    "        validauc[i]=np.mean(vv)\n",
    "    paramtable = pd.DataFrame({\n",
    "        'TrainingSet': trainauc,\n",
    "        'ValidationSet': validauc\n",
    "    }, columns=['TrainingSet', 'ValidationSet'], index=pd.Index(paramlst, name=param))\n",
    "    print(paramtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TrainingSet  ValidationSet\n",
      "step_size                            \n",
      "0.10          0.633931       0.630944\n",
      "0.05          0.639026       0.635908\n",
      "0.01          0.611031       0.609930\n"
     ]
    }
   ],
   "source": [
    "cv_fm('step_size', [0.1, 0.05, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
